<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.24.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Machine Learning (Part 2) [OLD VERSION] - Pharath Palesuvaran</title>
<meta name="description" content="[OLD VERSION!] Notes on Machine Learning theory. Based on C. M. Bishop, “Pattern Recognition and Machine Learning” (2011) and Goodfellow, Bengio, Courville, “Deep Learning”.">


  <meta name="author" content="Pharath Palesuvaran">
  
  <meta property="article:author" content="Pharath Palesuvaran">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Pharath Palesuvaran">
<meta property="og:title" content="Machine Learning (Part 2) [OLD VERSION]">
<meta property="og:url" content="http://localhost:4000/lecture_notes/machine_learning/lecture-notes-ML-part2-old/">


  <meta property="og:description" content="[OLD VERSION!] Notes on Machine Learning theory. Based on C. M. Bishop, “Pattern Recognition and Machine Learning” (2011) and Goodfellow, Bengio, Courville, “Deep Learning”.">



  <meta property="og:image" content="http://localhost:4000/assets/images/lenet.png">





  <meta property="article:published_time" content="2022-03-09T00:00:00+01:00">






<link rel="canonical" href="http://localhost:4000/lecture_notes/machine_learning/lecture-notes-ML-part2-old/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": null,
      "url": "http://localhost:4000/"
    
  }
</script>







<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Pharath Palesuvaran Feed">


<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<link rel="apple-touch-icon" sizes="180x180" href="https://raw.githubusercontent.com/pharath/home/master/assets/favicons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://raw.githubusercontent.com/pharath/home/master/assets/favicons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://raw.githubusercontent.com/pharath/home/master/assets/favicons/favicon-16x16.png">
<link rel="manifest" href="https://raw.githubusercontent.com/pharath/home/master/assets/favicons/site.webmanifest">
<link rel="shortcut icon" href="https://raw.githubusercontent.com/pharath/home/master/assets/favicons/favicon.ico">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="msapplication-config" content="https://raw.githubusercontent.com/pharath/home/master/assets/favicons/browserconfig.xml">
<meta name="theme-color" content="#ffffff">

<script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); </script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\(","\\)"] ],
    },
		TeX: {
    	Macros: {
				bra: ["\\langle{#1}|", 1],
				ket: ["|{#1}\\rangle", 1],
        braket: ["\\langle{#1}\\rangle", 1],
				bk: ["\\langle{#1}|{#2}|{#3}\\rangle", 3]
    	}
  	}
	});

</script>
<!--
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/latest.js?config=TeX-MML-AM_CHTML' async></script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-MML-AM_CHTML' async></script>
-->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-MML-AM_CHTML' async></script>

<!-- end custom head snippets -->

  </head>

  <body class="layout--single wide">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
          <a class="site-logo" href="/"><img src="/assets/images/pytorch-logo.png" alt="Pharath Palesuvaran"></a>
        
        <a class="site-title" href="/">
          Pharath Palesuvaran
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/posts/">Posts</a>
            </li><li class="masthead__menu-item">
              <a href="/categories/">Categories</a>
            </li><li class="masthead__menu-item">
              <a href="/tags/">Tags</a>
            </li><li class="masthead__menu-item">
              <a href="/about/">About</a>
            </li></ul>
        
        <button class="search__toggle" type="button" accesskey="s">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      
  







<div class="page__hero--overlay"
  style=" background-image: linear-gradient(rgba(0, 0, 0, 0.6), rgba(0, 0, 0, 0.6)), url('/assets/images/lenet.png');"
>
  
    <div class="wrapper">
      <h1 id="page-title" class="page__title" itemprop="headline">
        
          Machine Learning (Part 2) [OLD VERSION]

        
      </h1>
      
        <p class="page__lead">[OLD VERSION!] Notes on Machine Learning theory. Based on C. M. Bishop, “Pattern Recognition and Machine Learning” (2011) and Goodfellow, Bengio, Courville, “Deep Learning”.
</p>
      
      

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2022-03-09T00:00:00+01:00">March 9, 2022</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          13 minute read
        
      </span>
    
  </p>


      
      
        <p>
        
          <a href="" class="btn btn--light-outline btn--large">Some Content</a>
        
      
    </div>
  
  
    <span class="page__hero-caption">Photo credit: <a href="http://yann.lecun.com/"><strong>Yann LeCun</strong></a>
</span>
  
</div>





<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person" class="h-card">

  
    <div class="author__avatar">
      <a href="http://localhost:4000/">
        <img src="/assets/images/profile_pic.jpg" alt="Pharath Palesuvaran" itemprop="image" class="u-photo">
      </a>
    </div>
  

  <div class="author__content">
    <h3 class="author__name p-name" itemprop="name">
      <a class="u-url" rel="me" href="http://localhost:4000/" itemprop="url">Pharath Palesuvaran</a>
    </h3>
    
      <div class="author__bio p-note" itemprop="description">
        <p>Machine Learning, Computer Vision, Self-driving cars and a very rusty first degree in Physics</p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="https://schema.org/Place">
          <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name" class="p-locality">Aachen (Germany)</span>
        </li>
      

      
        
          
            <li><a href="mailto:phrth2@gmail.com" rel="nofollow noopener noreferrer me"><i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i><span class="label">Email</span></a></li>
          
        
          
        
          
            <li><a href="https://twitter.com/pharath_one" rel="nofollow noopener noreferrer me"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i><span class="label">Twitter</span></a></li>
          
        
          
            <li><a href="https://github.com/pharath" rel="nofollow noopener noreferrer me"><i class="fab fa-fw fa-github" aria-hidden="true"></i><span class="label">GitHub</span></a></li>
          
        
          
            <li><a href="/_pages/404.md" rel="nofollow noopener noreferrer me"><i class="fab fa-fw fa-instagram" aria-hidden="true"></i><span class="label">Instagram</span></a></li>
          
        
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer me">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>
  
  </div>



  <article class="page h-entry" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Machine Learning (Part 2) [OLD VERSION]">
    <meta itemprop="description" content="[OLD VERSION!] Notes on Machine Learning theory. Based on C. M. Bishop, “Pattern Recognition and Machine Learning” (2011) and Goodfellow, Bengio, Courville, “Deep Learning”.">
    <meta itemprop="datePublished" content="2022-03-09T00:00:00+01:00">
    

    <div class="page__inner-wrap">
      

      <section class="page__content e-content" itemprop="text">
        
          <aside class="sidebar__right ">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> Contents</h4></header>
              <ul class="toc__menu"><li><a href="#neural-networks">Neural Networks</a><ul><li><a href="#perceptrons-rosenblatt-1962">Perceptrons (Rosenblatt 1962)</a></li><li><a href="#terminology">Terminology</a></li><li><a href="#automatic-differentiation">Automatic Differentiation</a><ul><li><a href="#forward-mode-vs-reverse-mode-differentiation">Forward-mode vs Reverse-mode differentiation</a></li><li><a href="#pytorch-autograd">PyTorch autograd</a></li></ul></li><li><a href="#forward-propagation">Forward Propagation</a></li><li><a href="#backprop">Backprop</a><ul><li><a href="#computational-graphs">Computational Graphs</a></li><li><a href="#dynamic-programming">Dynamic Programming</a><ul><li><a href="#example-fibonacci-sequence">Example: Fibonacci sequence</a></li><li><a href="#relation-to-backprop">Relation to Backprop</a></li></ul></li></ul></li><li><a href="#implementing-softmax-correctly">Implementing Softmax Correctly</a></li><li><a href="#mlp-in-numpy-from-scratch">MLP in numpy from scratch</a></li><li><a href="#stochastic-learning-vs-batch-learning">Stochastic Learning vs Batch Learning</a><ul><li><a href="#sgd">SGD</a></li><li><a href="#batch-gd">Batch GD</a></li><li><a href="#mini-batch-gd">Mini-batch GD</a></li><li><a href="#shuffling-the-examples">Shuffling the Examples</a></li></ul></li></ul></li></ul>

            </nav>
          </aside>
        
        <h1 id="neural-networks">Neural Networks</h1>

<h2 id="perceptrons-rosenblatt-1962">Perceptrons (Rosenblatt 1962)</h2>

<ul>
  <li>perceptrons are <strong>generalized linear models</strong> (“generalized” because of the activation function)
    <ul>
      <li><strong>BUT</strong>: Deep Neural Networks are <strong>nonlinear parametric models</strong>.</li>
    </ul>
  </li>
  <li>more specifically: perceptrons are <strong>generalized linear discriminants</strong> (because they map the input <strong>x</strong> directly to a class label t in {-1,+1} [see above: “Linear models for classification”: approach 1.])</li>
  <li>original version:
    <ul>
      <li>2-class linear discriminant</li>
      <li>with fixed [i.e. not learned!] nonlinear transformation $\vec{\phi}(\pmb{x})$</li>
      <li>activation function: step function</li>
      <li>learned via minimization of “<strong>perceptron criterion</strong>” $\Rightarrow$ SGD</li>
      <li>exact solution guaranteed for linearly separable data set (<strong>Perceptron Convergence Theorem</strong>)
        <ul>
          <li><strong>BUT:</strong> in practice, convergence can be slow
            <ul>
              <li>it’s hard to decide, if a problem is not linearly separable or just slowly converging!</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="terminology">Terminology</h2>

<ul>
  <li>
    <p><strong>Input layer</strong> is a layer, it’s not wrong to say that. <a href="https://datascience.stackexchange.com/a/14033/115254">source</a></p>
  </li>
  <li>
    <p>However, when calculating the <strong>depth</strong> of a deep neural network, we only consider the layers that have tunable weights. <a href="https://datascience.stackexchange.com/a/14033/115254">source</a></p>
  </li>
</ul>

<h2 id="automatic-differentiation">Automatic Differentiation</h2>

<h3 id="forward-mode-vs-reverse-mode-differentiation">Forward-mode vs Reverse-mode differentiation</h3>

<ul>
  <li>read <a href="https://colah.github.io/posts/2015-08-Backprop/">Olah</a></li>
</ul>

<blockquote>
  <p><strong>Forward-mode differentiation</strong> starts at an input to the graph and moves towards the end. At every node, it sums all the paths feeding in. Each of those paths represents one way in which the input affects that node. By adding them up, we get the total way in which the node is affected by the input, it’s derivative. […]</p>
</blockquote>

<blockquote>
  <p><strong>Reverse-mode differentiation</strong>, on the other hand, starts at an output of the graph and moves towards the beginning. At each node, it merges all paths which originated at that node. […]</p>
</blockquote>

<blockquote>
  <p>When I say that reverse-mode differentiation gives us the derivative of e with respect to every node, I really do mean <strong>every node</strong>. We get both $\frac{\partial e}{\partial a}$ and $\frac{\partial e}{\partial b}$, the derivatives of $e$ with respect to both inputs. Forward-mode differentiation gave us the derivative of our output with respect to a single input, but reverse-mode differentiation gives us all of them. […]</p>
</blockquote>

<blockquote>
  <p>When training neural networks, we think of the cost (a value describing how bad a neural network performs) as a function of the parameters (numbers describing how the network behaves). We want to calculate the derivatives of the <strong>cost with respect to all the parameters</strong>, for use in gradient descent. Now, there’s often millions, or even tens of millions of parameters in a neural network. So, <strong>reverse-mode differentiation, <mark>called</mark> backpropagation</strong> [<a href="#reverse_mode_accumulation">more precise: reverse_mode_accumulation</a>] in the context of neural networks, gives us a massive speed up!</p>
</blockquote>

<blockquote>
  <p>(Are there any cases <strong>where forward-mode differentiation makes more sense</strong>? Yes, there are! Where the reverse-mode gives the derivatives of one output with respect to all inputs, the forward-mode gives us the derivatives of all outputs with respect to one input. If one has a function with lots of outputs, forward-mode differentiation can be much, much, much faster.)</p>
</blockquote>

<ul>
  <li>both are algorithms for efficiently computing the sum by factoring the paths. Instead of summing over all of the paths explicitly, they compute the same sum more efficiently by <mark>**merging paths back together at every node**</mark>. In fact, <strong>both</strong> algorithms touch each edge exactly once!
    <ul>
      <li>At each node, reverse-mode differentiation merges all paths which <strong>originated</strong> at that node (starting at an output of the graph and moving towards the beginning)</li>
      <li>At each node, forward-mode differentiation sums all the paths <strong>feeding into</strong> that node (starting at the beginning and moving towards an output of the graph)</li>
    </ul>
  </li>
  <li>forward-mode: apply operator $\frac{\partial}{\partial X}$</li>
  <li>reverse-mode: apply operator $\frac{\partial Z}{\partial}$</li>
  <li>if we have e.g. a hundred inputs, but only one output, reverse-mode differentiation gives a speed up in $\mathcal{O}(\text{# Inputs})$ compared to forward-mode differentiation</li>
</ul>

<h3 id="pytorch-autograd">PyTorch autograd</h3>

<p><a href="https://pytorch.org/tutorials/beginner/pytorch_with_examples.html">source: Justin Johnson</a></p>

<ul>
  <li>In the above examples, we had to <strong>manually</strong> implement both the forward and backward passes of our neural network. Manually implementing the backward pass is not a big deal for a small two-layer (?: siehe Stichpunkt) network, but can quickly get very hairy for large complex networks.
    <ul>
      <li>?: Why “two-layer”:
        <ul>
          <li>The previous polynomial regression examples correspond to a <strong>single</strong> layer perceptron with a fixed nonlinear transformation of the inputs (here: using polynomial basis functions), so why does Johnson say <strong>two</strong>-layer perceptron?
            <ul>
              <li>What Johnson probably means here is that, basically, implementing backprop <strong>manually</strong> (like in the previous polynomial regression examples) for a two-layer NN would be possible without autograd. This “two-layer network”, however, does not refer to the previous polynomial regression models!</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">autograd</code> computes <strong>all</strong> gradients with only one line <code class="language-plaintext highlighter-rouge">loss.backward()</code>.
    <ul>
      <li>in polynomial regression example <strong>without</strong> <code class="language-plaintext highlighter-rouge">autograd</code>:
        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="n">grad_a</span> <span class="o">=</span> <span class="n">grad_y_pred</span><span class="p">.</span><span class="nb">sum</span><span class="p">()</span>
  <span class="n">grad_b</span> <span class="o">=</span> <span class="p">(</span><span class="n">grad_y_pred</span> <span class="o">*</span> <span class="n">x</span><span class="p">).</span><span class="nb">sum</span><span class="p">()</span>
  <span class="n">grad_c</span> <span class="o">=</span> <span class="p">(</span><span class="n">grad_y_pred</span> <span class="o">*</span> <span class="n">x</span> <span class="o">**</span> <span class="mi">2</span><span class="p">).</span><span class="nb">sum</span><span class="p">()</span>
  <span class="n">grad_d</span> <span class="o">=</span> <span class="p">(</span><span class="n">grad_y_pred</span> <span class="o">*</span> <span class="n">x</span> <span class="o">**</span> <span class="mi">3</span><span class="p">).</span><span class="nb">sum</span><span class="p">()</span>
</code></pre></div>        </div>
      </li>
      <li>the same <strong>with</strong> <code class="language-plaintext highlighter-rouge">autograd</code>:
        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
</code></pre></div>        </div>
        <p>where all parameter tensors must have <code class="language-plaintext highlighter-rouge">requires_grad = True</code> (otherwise <code class="language-plaintext highlighter-rouge">autograd</code> does not know wrt which parameters <code class="language-plaintext highlighter-rouge">loss</code> must be differentiated).</p>
      </li>
    </ul>
  </li>
  <li>Thankfully, we can use <strong>automatic differentiation</strong> to automate the computation of backward passes in neural networks. The <strong>autograd</strong> package in PyTorch provides exactly this functionality. When using autograd, the forward pass of your network will define a <strong>computational graph</strong>; nodes in the graph will be Tensors, and edges will be functions that produce output Tensors from input Tensors. Backpropagating through this graph then allows you to easily compute gradients.
    <ul>
      <li>auf Folie:
        <ol>
          <li>Convert NN to a computational graph
            <ul>
              <li>explanations:
                <ul>
                  <li><a href="https://blog.paperspace.com/pytorch-101-understanding-graphs-and-automatic-differentiation/">PyTorch 101, Part 1: Understanding Graphs, Automatic Differentiation and Autograd</a>
                    <ul>
                      <li><a href="/pytorch/machine_learning/notes-pytorch/#how-does-pytorch-create-a-computational-graph">important points from this blog post</a></li>
                    </ul>
                  </li>
                  <li><a href="https://towardsdatascience.com/computational-graphs-in-pytorch-and-tensorflow-c25cc40bdcd1">Computational graphs in PyTorch and TensorFlow</a></li>
                </ul>
              </li>
            </ul>
          </li>
          <li>Each new layer/module specifies how it affects the forward and backward passes
            <ul>
              <li>auf nächster Folie: “Each module is defined by
                <ul>
                  <li><code class="language-plaintext highlighter-rouge">module.fprop(</code>$x$<code class="language-plaintext highlighter-rouge">)</code></li>
                  <li><code class="language-plaintext highlighter-rouge">module.bprop(</code>$\frac{\partial E}{\partial y}$<code class="language-plaintext highlighter-rouge">)</code>
                    <ul>
                      <li>computes the gradients of the cost wrt. the inputs $x$ given the gradient wrt. the outputs $y$</li>
                      <li><code class="language-plaintext highlighter-rouge">module.bprop()</code> ist in PyTorch wegen dem Autograd System nicht notwendig (vgl. <a href="/pytorch/machine_learning/notes-pytorch/#modules">aus PyTorch Doc</a>)</li>
                    </ul>
                  </li>
                </ul>
              </li>
              <li>e.g. <code class="language-plaintext highlighter-rouge">torch.nn.Linear</code> specifies that it will apply a linear transformation $y=xA^T+b$ to the incoming data during the forward pass (each module has a <code class="language-plaintext highlighter-rouge">forward()</code> method, see e.g. <a href="https://pytorch.org/docs/stable/_modules/torch/nn/modules/linear.html#Linear">source nn.Linear</a>)</li>
            </ul>
          </li>
          <li>Apply reverse-mode differentiation
            <ul>
              <li>i.e. call <code class="language-plaintext highlighter-rouge">loss.backward()</code></li>
            </ul>
          </li>
        </ol>
      </li>
    </ul>
  </li>
  <li>This sounds complicated, it’s pretty simple to use in practice. Each Tensor represents a node in a computational graph. If <code class="language-plaintext highlighter-rouge">x</code> is a Tensor that has <code class="language-plaintext highlighter-rouge">x.requires_grad=True</code> then <code class="language-plaintext highlighter-rouge">x.grad</code> is another Tensor holding the gradient of <code class="language-plaintext highlighter-rouge">x</code> with respect to some scalar value.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># -*- coding: utf-8 -*-
</span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">math</span>


<span class="c1"># Create Tensors to hold input and outputs.
</span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="n">math</span><span class="p">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">math</span><span class="p">.</span><span class="n">pi</span><span class="p">,</span> <span class="mi">2000</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># For this example, the output y is a linear function of (x, x^2, x^3), so
# we can consider it as a linear layer neural network. Let's prepare the
# tensor (x, x^2, x^3).
</span><span class="n">p</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">xx</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">).</span><span class="nb">pow</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

<span class="c1"># In the above code, x.unsqueeze(-1) has shape (2000, 1), and p has shape
# (3,), for this case, broadcasting semantics will apply to obtain a tensor
# of shape (2000, 3)
</span>
<span class="c1"># Use the nn package to define our model as a sequence of layers. nn.Sequential
# is a Module which contains other Modules, and applies them in sequence to
# produce its output. The Linear Module computes output from input using a
# linear function, and holds internal Tensors for its weight and bias.
# The Flatten layer flatens the output of the linear layer to a 1D tensor,
# to match the shape of `y`.
</span><span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Flatten</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># The nn package also contains definitions of popular loss functions; in this
# case we will use Mean Squared Error (MSE) as our loss function.
</span><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">MSELoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s">'sum'</span><span class="p">)</span>

<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1e-6</span>
<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2000</span><span class="p">):</span>

    <span class="c1"># Forward pass: compute predicted y by passing x to the model. Module objects
</span>    <span class="c1"># override the __call__ operator so you can call them like functions. When
</span>    <span class="c1"># doing so you pass a Tensor of input data to the Module and it produces
</span>    <span class="c1"># a Tensor of output data.
</span>    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">xx</span><span class="p">)</span>

    <span class="c1"># Compute and print loss. We pass Tensors containing the predicted and true
</span>    <span class="c1"># values of y, and the loss function returns a Tensor containing the
</span>    <span class="c1"># loss.
</span>    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">t</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">99</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">loss</span><span class="p">.</span><span class="n">item</span><span class="p">())</span>

    <span class="c1"># Zero the gradients before running the backward pass.
</span>    <span class="n">model</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>

    <span class="c1"># Backward pass: compute gradient of the loss with respect to all the learnable
</span>    <span class="c1"># parameters of the model. Internally, the parameters of each Module are stored
</span>    <span class="c1"># in Tensors with requires_grad=True, so this call will compute gradients for
</span>    <span class="c1"># all learnable parameters in the model.
</span>    <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>

    <span class="c1"># Update the weights using gradient descent. Each parameter is a Tensor, so
</span>    <span class="c1"># we can access its gradients like we did before.
</span>    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="n">param</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">param</span><span class="p">.</span><span class="n">grad</span>

<span class="c1"># You can access the first layer of `model` like accessing the first item of a list
</span><span class="n">linear_layer</span> <span class="o">=</span> <span class="n">model</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># For linear layer, its parameters are stored as `weight` and `bias`.
</span><span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'Result: y = </span><span class="si">{</span><span class="n">linear_layer</span><span class="p">.</span><span class="n">bias</span><span class="p">.</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s"> + </span><span class="si">{</span><span class="n">linear_layer</span><span class="p">.</span><span class="n">weight</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">].</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s"> x + </span><span class="si">{</span><span class="n">linear_layer</span><span class="p">.</span><span class="n">weight</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">].</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s"> x^2 + </span><span class="si">{</span><span class="n">linear_layer</span><span class="p">.</span><span class="n">weight</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">].</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s"> x^3'</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="forward-propagation">Forward Propagation</h2>

<ul>
  <li>inputs:
    <ul>
      <li>depth $l$</li>
      <li>$l$ weight matrices of the model $\mathbf{W}^{(i)}$</li>
      <li>$l$ biases of the model $\mathbf{b}^{(i)}$</li>
      <li>input $\mathbf{x}$ (here: only one for simplicity)</li>
      <li>target $\mathbf{y}$</li>
    </ul>
  </li>
  <li>outputs:
    <ul>
      <li>output $\hat{\mathbf{y}}$</li>
      <li>cost function $J$</li>
      <li>input of unit $j$: $\mathbf{a}_j^{(k)}$ for all $j$</li>
      <li>output of unit $j$: $\mathbf{h}_j^{(k)}$ for all $j$</li>
    </ul>
  </li>
</ul>

<h2 id="backprop">Backprop</h2>

<ul>
  <li>inputs:
    <ul>
      <li>depth l</li>
      <li>l weight matrices of the model $\mathbf{W}^{(i)}$</li>
      <li>l biases of the model $\mathbf{b}^{(i)}$</li>
      <li>outputs of Forward Propagation</li>
    </ul>
  </li>
  <li>outputs:
    <ul>
      <li>gradients w.r.t. all weights and biases $\nabla_{\mathbf{W}^{(k)}}J$ and $\nabla_{\mathbf{b}^{(k)}}J$
        <ul>
          <li>also computes all $\nabla_{\mathbf{a}^{(k)}}J$ and $\nabla_{\mathbf{h}^{(k)}}J$ in the process
            <ul>
              <li>$\nabla_{\mathbf{a}^{(k)}}J$ can be interpreted as an indication of how each layer’s output should change to reduce error
                <ul>
                  <li>es gibt ein $\nabla_{\mathbf{a}^{(k)}}J$ pro layer k: jede unit in layer k entspricht einer Komponente von $\nabla_{\mathbf{a}^{(k)}}J$</li>
                </ul>
              </li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>refers only to the <strong>method used to compute all necessary gradients</strong>, whereas another algorithm (e.g. SGD) is used to perform <strong>learning</strong> using these gradients!
    <ul>
      <li>“however, the term is often used loosely to refer to the entire learning algorithm, including how the gradient is used, such as by stochastic gradient descent” <a href="https://en.wikipedia.org/wiki/Backpropagation">source</a>
 	&gt; <a name="reverse_mode_accumulation"></a>“More generally, the field of <strong>automatic differentiation</strong> is concerned with how to compute derivatives algorithmically. The back-propagation algorithm described here is only one approach to automatic differentiation. It is a special case of a broader class of techniques called <strong>reverse mode accumulation</strong>.” (Goodfellow, Bengio)</li>
    </ul>
  </li>
  <li>“layer below builds upon (gradient) result of layer above” (basically, chain rule)
    <ul>
      <li>this is why it’s called “backprop”</li>
      <li>“propagates the gradient backwards through the layers”</li>
    </ul>
  </li>
  <li>“performs on the order of one <strong>Jacobian product</strong> per node in the graph” (Goodfellow, Bengio)
    <ul>
      <li>This can be seen from the fact that Backprop visits each edge (of the computational graph for this problem) only once</li>
    </ul>
  </li>
  <li>“[…] the amount of computation required for performing the back-propagation <strong>scales linearly with the number of edges</strong> in $\mathcal{G}$, where the computation <strong>for each edge</strong> corresponds to computing
    <ul>
      <li>a partial derivative (of one node with respect to one of its parents) as well as performing</li>
      <li>one multiplication and</li>
      <li>one addition.” (Goodfellow, Bengio)</li>
    </ul>
  </li>
</ul>

<h3 id="computational-graphs">Computational Graphs</h3>

<ul>
  <li>the following texts from <a href="#Goodfellow_2016">Goodfellow_2016</a> describe the same graphs as Olah is describing in his <a href="https://colah.github.io/posts/2015-08-Backprop/">blog post</a>
    <ul>
      <li>“That algorithm specifies the <strong>forward propagation</strong> computation, which we could put in a graph $\mathcal{G}$. In order to perform <strong>back-propagation</strong>, we can construct a computational graph that depends on $\mathcal{G}$ and adds to it an extra set of nodes. These form a <strong>subgraph</strong> $\mathcal{B}$ with one node per node of $\mathcal{G}$. Computation in $\mathcal{B}$ proceeds in exactly the reverse of the order of computation in $\mathcal{B}$, and each node of $\mathcal{B}$ computes the derivative $\frac{\partial u^{(n)}}{\partial u^{(i)}}$ associated with the <strong>forward graph</strong> node $u^{(i)}$.” (Goodfellow, Bengio)</li>
      <li>“The subgraph $\mathcal{B}$ contains exactly one edge for each edge from node $u^{(j)}$ to node $u^{(i)}$ of $\mathcal{G}$.” (Goodfellow, Bengio)</li>
    </ul>
  </li>
</ul>

<h3 id="dynamic-programming">Dynamic Programming</h3>

<ul>
  <li>a computer programming method
    <ul>
      <li>though, in literature one often finds the plural form “dynamic programming methods”</li>
    </ul>
  </li>
  <li>refers to simplifying a complicated problem by breaking it down into simpler sub-problems in a recursive manner
    <ul>
      <li>if this “breaking down” is possible for a problem, then the problem is said to have <strong>optimal substructure</strong></li>
    </ul>
  </li>
</ul>

<h4 id="example-fibonacci-sequence">Example: Fibonacci sequence</h4>

<p>source: <a href="https://en.wikipedia.org/wiki/Dynamic_programming#Fibonacci_sequence">https://en.wikipedia.org/wiki/Dynamic_programming#Fibonacci_sequence</a></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">var</span> <span class="n">m</span> <span class="p">:</span><span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="mi">0</span> <span class="err">→</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span> <span class="err">→</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">function</span> <span class="n">fib</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">key</span> <span class="n">n</span> <span class="ow">is</span> <span class="ow">not</span> <span class="ow">in</span> <span class="nb">map</span> <span class="n">m</span>
        <span class="n">m</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="p">:</span><span class="o">=</span> <span class="n">fib</span><span class="p">(</span><span class="n">n</span> <span class="err">−</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">fib</span><span class="p">(</span><span class="n">n</span> <span class="err">−</span> <span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">m</span><span class="p">[</span><span class="n">n</span><span class="p">]</span>
</code></pre></div></div>

<ul>
  <li>This technique of saving values that have already been calculated is called <strong>memoization</strong></li>
  <li>The function requires only $\mathcal{O}(n)$ time instead of <strong>exponential time</strong> (but requires $\mathcal{O}(n)$ space)
    <ul>
      <li>i.e. the number of common subexpressions is reduced <strong>without regard to memory</strong>!</li>
      <li>note: sometimes recalculating instead of storing can be a good decision, <strong>if memory is limited</strong>!</li>
    </ul>
  </li>
</ul>

<h4 id="relation-to-backprop">Relation to Backprop</h4>

<ul>
  <li>Backprop stores the $y_i^{(k-1)}$ during the forward pass and re-uses it during the backward pass to calculate $\frac{\partial E}{\partial w_{ji}^{(k-1)}}=y_i^{(k-1)}\frac{\partial E}{\partial w_{ji}^{(k-1)}}$ (memoization, Dynamic Programming)</li>
  <li>During the backward pass Backprop visits each edge only once (see above) and gradients that have already been calculated are saved in memory (cf. <code class="language-plaintext highlighter-rouge">grad_table[u[i]]</code> in Algo 6.2 or <code class="language-plaintext highlighter-rouge">g</code> in Algo 6.4 Goodfellow, Bengio)! (memoization, Dynamic Programming)
    <ul>
      <li>this is analogous to the Fibonacci Sequence Algo’s map <code class="language-plaintext highlighter-rouge">m</code> (see above) which saves the <code class="language-plaintext highlighter-rouge">fib(n − 1) + fib(n − 2)</code> that have already been calculated in memory</li>
    </ul>
  </li>
  <li>(cf. Figure 6.9 in Goodfellow, Bengio) Back-propagation avoids the exponential explosion in <strong>repeated subexpressions</strong></li>
  <li>similar to the Fibonacci example “the back-propagation algorithm is designed to reduce the number of common subexpressions <strong>without regard to memory</strong>.” (Goodfellow, Bengio)</li>
  <li>“When the memory required to store the value of these expressions is low, the back-propagation approach of equation 6.52 <img src="/assets/images/goodfellow_ml/Goodf_6_50-6_53.png" alt="6.52" /> is clearly preferable because of its reduced runtime. However, equation 6.53 is also a valid implementation of the chain rule, and is useful <strong>when memory is limited</strong>.” (Goodfellow, Bengio)</li>
</ul>

<h2 id="implementing-softmax-correctly">Implementing Softmax Correctly</h2>

<ul>
  <li>Problem: Exponentials get very big and can have very different magnitudes
    <ul>
      <li>Solution:
        <ul>
          <li>Evaluate $\ln{(\sum_{j=1}^K\exp{(\mathbf{w}_j^\top\mathbf{x})})}$ in the denominator <strong>before</strong> calculating the fraction</li>
          <li>since $\text{softmax}(\mathbf{a} + \mathbf{b}) = \text{softmax}(\mathbf{a})$ for all $\mathbf{b}\in\mathbb{R}^D$, one can subtract the largest $\mathbf{w}_j$ from the others
            <ul>
              <li>(entspricht $\mathbf{a}=\mathbf{w}_j^\top\mathbf{x}$ und $\mathbf{b}=\mathbf{w}_M^\top\mathbf{x}$ bzw. Kürzen des Bruches mit $\exp{(\mathbf{w}_M^\top\mathbf{x})}$, wobei $\mathbf{w}_M$ das größte weight ist)</li>
              <li>(egal, ob $\mathbf{b}$ von $\mathbf{x}$ abhängt oder nicht!)</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="mlp-in-numpy-from-scratch">MLP in numpy from scratch</h2>

<ul>
  <li>see <a href="https://htmlpreview.github.io/?https://github.com/pharath/home/blob/master/_posts_html/notebooks_in_html/Expl_NN_in_numpy_copy.html">here</a></li>
</ul>

<h2 id="stochastic-learning-vs-batch-learning">Stochastic Learning vs Batch Learning</h2>

<p>source: LeCun et al. “Efficient BackProp”</p>

<h3 id="sgd">SGD</h3>

<ul>
  <li>Pros:
    <ul>
      <li>is usually much faster than batch learning
        <ul>
          <li>consider large redundant data set
            <ul>
              <li>example: training set of size 1000 is inadvertently composed of 10 identical copies of a set with 100 samples</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>also often results in better solutions because of the noise in the updates
        <ul>
          <li>because the noise present in the updates can result in the weights jumping into the basin of another, possibly deeper, local minimum. This has been demonstrated in certain simplified cases</li>
        </ul>
      </li>
      <li>can be used for tracking changes
        <ul>
          <li>useful when the function being modeled is changing over time</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Cons:
    <ul>
      <li>noise also prevents full convergence to the minimum
        <ul>
          <li>Instead of converging to the exact minimum, the convergence stalls out due to the <strong>weight fluctuations</strong></li>
          <li>size of the fluctuations depend on the degree of noise of the stochastic updates:
            <ul>
              <li>The variance of the fluctuations around the local minimum is proportional to the learning rate $\eta$</li>
              <li>So in order <strong>to reduce the fluctuations</strong> we can either
                <ul>
                  <li>decrease (anneal) the learning rate or</li>
                  <li>have an adaptive batch size.</li>
                </ul>
              </li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="batch-gd">Batch GD</h3>

<ul>
  <li>Pros:
    <ul>
      <li>Conditions of convergence are well understood.</li>
      <li>Many acceleration techniques (e.g. conjugate gradient) only operate in batch learning.
   	- Theoretical analysis of the weight dynamics and convergence rates are simpler</li>
      <li>one is able to use second order methods to speed the learning process
        <ul>
          <li>Second order methods speed learning by estimating not just the gradient but also the curvature of the cost surface. Given the curvature, one can estimate the approximate location of the actual minimum.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Cons:
    <ul>
      <li>redundancy can make batch learning much slower than on-line</li>
      <li>often results in worse solutions because of the absence of noise in the updates
        <ul>
          <li>will discover the minimum of whatever basin the weights are initially placed</li>
        </ul>
      </li>
      <li>changes go undetected and we obtain rather bad results since we are likely to average over several rules</li>
    </ul>
  </li>
</ul>

<h3 id="mini-batch-gd">Mini-batch GD</h3>

<ul>
  <li>Another method to remove noise [in SGD] is to use “mini-batches”, that is, start with a small batch size and increase the size as training proceeds.
    <ul>
      <li>However, deciding the rate at which to increase the batch size and which inputs to include in the small batches is as difficult as determining the proper learning rate. <strong>Effectively the size of the learning rate in stochastic learning corresponds to the respective size of the mini batch.</strong></li>
    </ul>
  </li>
  <li>Note also that the problem of removing the noise in the data may be less critical than one thinks because of generalization. <strong>Overtraining may occur long before the noise regime is even reached.</strong></li>
</ul>

<h3 id="shuffling-the-examples">Shuffling the Examples</h3>

<ul>
  <li><a href="https://nbviewer.org/github/pharath/home/blob/master/assets/notebooks/Expl_NN_in_numpy.ipynb">Expl_NN_in_numpy</a></li>
  <li><a href="https://nbviewer.org/github/pharath/home/blob/master/assets/notebooks/MLP_in_numpy.ipynb">MLP_in_numpy</a></li>
  <li><a href="https://nbviewer.org/github/pharath/home/blob/master/assets/notebooks/MLP_selbst_versucht.ipynb">MLP_selbst_versucht</a></li>
  <li><a href="https://nbviewer.org/github/pharath/home/blob/master/assets/notebooks/WofuerIst__name__gut.ipynb">WofuerIst__name__gut</a></li>
</ul>


        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#lecture-notes" class="page__taxonomy-item p-category" rel="tag">lecture_notes</a><span class="sep">, </span>
    
      <a href="/tags/#ml" class="page__taxonomy-item p-category" rel="tag">ml</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#lecture-notes" class="page__taxonomy-item p-category" rel="tag">Lecture_Notes</a><span class="sep">, </span>
    
      <a href="/categories/#machine-learning" class="page__taxonomy-item p-category" rel="tag">Machine_Learning</a>
    
    </span>
  </p>


        

  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time class="dt-published" datetime="2022-03-09T00:00:00+01:00">March 9, 2022</time></p>

      </footer>

      <section class="page__share">
  

  <a href="https://twitter.com/intent/tweet?text=Machine+Learning+%28Part+2%29+%5BOLD+VERSION%5D%20http%3A%2F%2Flocalhost%3A4000%2Flecture_notes%2Fmachine_learning%2Flecture-notes-ML-part2-old%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2Flocalhost%3A4000%2Flecture_notes%2Fmachine_learning%2Flecture-notes-ML-part2-old%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=http%3A%2F%2Flocalhost%3A4000%2Flecture_notes%2Fmachine_learning%2Flecture-notes-ML-part2-old%2F" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/notes/machine_learning/notes-Neuroscience/" class="pagination--pager" title="New Inspirations for Machine Learning Methods
">Previous</a>
    
    
      <a href="#" class="pagination--pager disabled">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
    <div class="page__related">
      <h2 class="page__related-title">You May Also Enjoy</h2>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/assets/images/lenet.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/notes/machine_learning/notes-Neuroscience/" rel="permalink">New Inspirations for Machine Learning Methods
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2022-02-26T00:00:00+01:00">February 26, 2022</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-fw fa-clock" aria-hidden="true"></i>
        
          less than 1 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Notes on some inspirations for Machine Learning methods. Based on opinions from leading scientists and also some of my own opinions.
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/assets/images/lenet.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/carla/simulator/self_driving/notes-Carla/" rel="permalink">Carla Simulator
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2022-02-17T00:00:00+01:00">February 17, 2022</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-fw fa-clock" aria-hidden="true"></i>
        
          less than 1 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Notes on the Carla Simulator
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/assets/images/lenet.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/lecture_notes/machine_learning/computer_vision/lecture-notes-ML-part3/" rel="permalink">Machine Learning (Part 3)
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2022-01-27T00:00:00+01:00">January 27, 2022</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-fw fa-clock" aria-hidden="true"></i>
        
          51 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Notes on Computer Vision theory and NLP. Based on Goodfellow, Bengio “Deep Learning”, Stanford CS231n and RWTH Aachen University Machine Learning
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/assets/images/mario-question.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/cheatsheet/cheatsheet-ros/" rel="permalink">ROS Cheatsheet
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2022-01-22T00:00:00+01:00">January 22, 2022</time>
      </span>
    

    

    
  </p>


    <p class="archive__item-excerpt" itemprop="description">roslaunch

roslaunch --ros-args /path/to/launchfile.launch

  Display command-line arguments for this launch file


&lt;launch&gt;
  &lt;!-- ros_args.launch ...</p>
  </article>
</div>

        
      </div>
    </div>
  
  
</div>
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';" role="search">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
          <li><a href="https://twitter.com/pharath_one" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
        
      
        
          <li><a href="https://github.com/pharath" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
          <li><a href="/_pages/404.md" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-instagram" aria-hidden="true"></i> Instagram</a></li>
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2022 Pharath Palesuvaran. </div>


      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>







  </body>
</html>
